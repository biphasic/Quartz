{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sinabs\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sinabs.layers as sl\n",
    "import numpy as np\n",
    "import quartz\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from quartz.utils import get_accuracy, encode_inputs, decode_outputs, plot_output_histograms, plot_output_comparison, normalize_weights\n",
    "from typing import List\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = torchvision.datasets.ImageNet('data/ImageNet/', split='val', transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(imagenet, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "cpu = \"cpu\"\n",
    "\n",
    "model = models.vgg11(weights=models.vgg.VGG11_Weights.DEFAULT)\n",
    "# model = models.vgg11_bn(weights=models.vgg.VGG11_BN_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Conv2d(3, 3, kernel_size=1, groups=3)\n",
    "layer1.weight.data /= layer1.weight.data\n",
    "layer1.bias = torch.nn.Parameter(-1*torch.tensor([0.485, 0.456, 0.406]))\n",
    "\n",
    "layer2 = nn.Conv2d(3, 3, kernel_size=1, groups=3)\n",
    "layer2.weight = nn.Parameter(1/torch.tensor([0.229, 0.224, 0.225]).unsqueeze(1).unsqueeze(1).unsqueeze(1))\n",
    "layer2.bias.data -= layer2.bias.data\n",
    "\n",
    "model = nn.Sequential(layer1, layer2, *model.features, model.avgpool, nn.Flatten(), *model.classifier[0:2], *model.classifier[3:5], model.classifier[-1]) #*model.classifier)\n",
    "model = model.eval()\n",
    "\n",
    "for layer in list(model.children())[2:]:\n",
    "    if isinstance(layer, nn.ReLU):\n",
    "        layer.inplace = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_accuracy(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model = copy.deepcopy(model)\n",
    "norm_model = norm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '5', '8', '10', '13', '15', '18', '20', '25', '27', '29']\n"
     ]
    }
   ],
   "source": [
    "param_layer_names = [name for name, child in norm_model.named_children() if isinstance(child, (nn.Conv2d, nn.Linear))][2:]\n",
    "# param_layers = ['2', '5', '8', '10', '13']\n",
    "percentile = 99.99\n",
    "\n",
    "print(param_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normloader = torch.utils.data.DataLoader(imagenet, batch_size=150, shuffle=True, num_workers=0)\n",
    "images, labels = next(iter(normloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_weights(norm_model.to(device), images.to(device), param_layer_names=param_layer_names, percentile=percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_output_comparison(model.to(cpu), norm_model.to(cpu), images.to(cpu), output_layers=param_layer_names, every_n=10000, every_c=10, savefig=f\"norm_activation_correct_biases.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_layer_names = [name for name, child in norm_model.named_children() if isinstance(child, nn.ReLU)]\n",
    "# output_layer_names += [param_layer_names[-1]]\n",
    "# sinabs.utils.normalize_weights(norm_model.to(device), images.to(device), param_layers=param_layer_names, output_layers=output_layer_names, percentile=percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfc54d42f7e4f0290552bb15431d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "68.10799837112427"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_accuracy(norm_model, testloader, device=device)#\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snnloader = torch.utils.data.DataLoader(imagenet, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "accuracies = []\n",
    "for exponent in range(4, 7):\n",
    "    t_max = 2**exponent\n",
    "    snn = quartz.from_torch.from_model(norm_model, t_max=t_max, add_spiking_output=True).eval()\n",
    "    preprocess_layers = norm_model[:4]\n",
    "    snn = snn[4:]\n",
    "    print(f\"percentile: {percentile}, t_max: {t_max}\")\n",
    "    accuracy = get_accuracy(snn, snnloader, device, preprocess=preprocess_layers, t_max=t_max, print_early_spikes=True, print_output_time=True)\n",
    "    np.save(f\"{accuracy}_accuracy_{t_max}_t_max.npy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "08ccb38fe61fa1a513d17600ee3143c806693551c71679f6a7a34d9dc326cda4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
