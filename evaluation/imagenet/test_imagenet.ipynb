{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sinabs\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sinabs.layers as sl\n",
    "import numpy as np\n",
    "import quartz\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from quartz.utils import get_accuracy, encode_inputs, decode_outputs, plot_output_histograms, plot_output_comparison, normalize_weights, count_n_neurons\n",
    "from typing import List\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = torchvision.datasets.ImageNet('data/ImageNet/', split='val', transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "testloader = torch.utils.data.DataLoader(imagenet, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "cpu = \"cpu\"\n",
    "\n",
    "model = models.vgg11(weights=models.vgg.VGG11_Weights.DEFAULT)\n",
    "# model = models.vgg11_bn(weights=models.vgg.VGG11_BN_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Conv2d(3, 3, kernel_size=1, groups=3)\n",
    "layer1.weight.data /= layer1.weight.data\n",
    "layer1.bias = torch.nn.Parameter(-1*torch.tensor([0.485, 0.456, 0.406]))\n",
    "\n",
    "layer2 = nn.Conv2d(3, 3, kernel_size=1, groups=3)\n",
    "layer2.weight = nn.Parameter(1/torch.tensor([0.229, 0.224, 0.225]).unsqueeze(1).unsqueeze(1).unsqueeze(1))\n",
    "layer2.bias.data -= layer2.bias.data\n",
    "\n",
    "model = nn.Sequential(layer1, layer2, *model.features, model.avgpool, nn.Flatten(), *model.classifier[0:2], *model.classifier[3:5], model.classifier[-1]) #*model.classifier)\n",
    "model = model.eval()\n",
    "\n",
    "for layer in list(model.children())[2:]:\n",
    "    if isinstance(layer, nn.ReLU):\n",
    "        layer.inplace = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_n_neurons(model.cpu(), next(iter(testloader))[0][:1], add_last_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "flops = FlopCountAnalysis(model, next(iter(testloader))[0])\n",
    "# flop_count_table(flops)\n",
    "print(flops.total()/1e6/batch_size)\n",
    "# flops.by_module_and_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_synops = 0.3e9\n",
    "n_neurons = 7_435_240\n",
    "t_max = 64\n",
    "\n",
    "n_operations = lambda n_neurons, t_max, n_synops: round((n_synops + 2*n_neurons*t_max)/1e6, 3)\n",
    "omega_read = lambda n_neurons, t_max, n_synops: round((4*n_neurons*t_max+n_synops)/1e6)\n",
    "omega_write = lambda n_neurons, t_max, n_synops: round((n_synops + n_neurons*t_max)/1e6)\n",
    "\n",
    "print(f\"Number of operations: {n_operations(n_neurons, t_max, n_synops)}M.\")\n",
    "print(f\"Read: {omega_read(n_neurons, t_max, n_synops)}M, write: {omega_write(n_neurons, t_max, n_synops)}M, total: {omega_read(n_neurons, t_max, n_synops)+omega_write(n_neurons, t_max, n_synops)}M\")\n",
    "\n",
    "[n_operations(n_neurons, 2**exponent, n_synops) for exponent in range(4,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model = copy.deepcopy(model)\n",
    "norm_model = norm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_layer_names = [name for name, child in norm_model.named_children() if isinstance(child, (nn.Conv2d, nn.Linear))][2:]\n",
    "# param_layers = ['2', '5', '8', '10', '13']\n",
    "percentile = 99.99\n",
    "\n",
    "print(param_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normloader = torch.utils.data.DataLoader(imagenet, batch_size=150, shuffle=True, num_workers=0)\n",
    "images, labels = next(iter(normloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_weights(norm_model.to(device), images.to(device), param_layer_names=param_layer_names, percentile=percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "flops = FlopCountAnalysis(norm_model, next(iter(testloader))[0])\n",
    "# flop_count_table(flops)\n",
    "print(flops.total()/1e6)\n",
    "# flops.by_module_and_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_output_comparison(model.to(cpu), norm_model.to(cpu), images.to(cpu), output_layers=param_layer_names, every_n=10000, every_c=10, savefig=f\"norm_activation_correct_biases.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_layer_names = [name for name, child in norm_model.named_children() if isinstance(child, nn.ReLU)]\n",
    "# output_layer_names += [param_layer_names[-1]]\n",
    "# sinabs.utils.normalize_weights(norm_model.to(device), images.to(device), param_layers=param_layer_names, output_layers=output_layer_names, percentile=percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_accuracy(norm_model, testloader, device=device)#\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snnloader = torch.utils.data.DataLoader(imagenet, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "accuracies = []\n",
    "for exponent in range(5, 8):\n",
    "    t_max = 2**exponent\n",
    "    snn = quartz.from_torch.from_model(norm_model, t_max=t_max, add_spiking_output=True).eval()\n",
    "    preprocess_layers = norm_model[:4]\n",
    "    snn = snn[4:]\n",
    "    print(f\"percentile: {percentile}, t_max: {t_max}\")\n",
    "    accuracy = get_accuracy(snn, snnloader, device, preprocess=preprocess_layers, t_max=t_max, print_early_spikes=True, print_output_time=True)\n",
    "    np.save(f\"{accuracy}_accuracy_{t_max}_t_max.npy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c00e5e7c7a569083cb991dfa106f557879cc0d1d84bf5b9d92fbb6bf680d358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
