{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sinabs\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import sinabs.layers as sl\n",
    "import numpy as np\n",
    "import quartz\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from quartz.utils import get_accuracy, encode_inputs, decode_outputs, remove_identity_layers, plot_output_histograms, normalize_outputs, plot_output_comparison, plot_output_comparison_new, normalize_weights, count_n_neurons, fuse_all_conv_bn\n",
    "from typing import List\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cifar10_models.mobilenetv2 import mobilenet_v2\n",
    "\n",
    "# model = mobilenet_v2(pretrained=True)\n",
    "# model = nn.Sequential(*model.features, nn.AvgPool2d(4), nn.Flatten(), *model.classifier)\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models.vgg import vgg11_bn\n",
    "\n",
    "model = vgg11_bn(pretrained=True)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models.resnet import resnet18\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_count = 0\n",
    "for module in model.modules():\n",
    "    if isinstance(module, (nn.ReLU, nn.ReLU6)):\n",
    "        module.inplace = False\n",
    "        relu_count += 1\n",
    "print(f\"Model contains {relu_count} relu layers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "valid_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, shuffle=False, batch_size=batch_size, num_workers=4)\n",
    "test_loader = DataLoader(dataset=valid_dataset, batch_size=1000, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folded_model = copy.deepcopy(model)\n",
    "fuse_all_conv_bn(folded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(folded_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_outputs(\n",
    "    model: nn.Module,\n",
    "    sample_data: torch.Tensor,\n",
    "    percentile: float = 99,\n",
    "    max_outputs = []\n",
    "):\n",
    "    def save_data(lyr, input, output):\n",
    "        # max_outputs.append(1.2)\n",
    "        max_outputs.append(np.percentile(output.cpu().numpy(), percentile))\n",
    "\n",
    "    module_input = []\n",
    "    def get_module_input(module, input, output):\n",
    "        module_input.append(input[0])\n",
    "\n",
    "    for name, module in model.named_children(): # immediate children\n",
    "        if list(module.named_children()): # is not empty (not a leaf)\n",
    "            handle = module.register_forward_hook(get_module_input)\n",
    "            with torch.no_grad():\n",
    "                model(sample_data)\n",
    "            sample_input = module_input[-1]\n",
    "            max_outputs = normalize_outputs(module, sample_input, percentile, max_outputs)\n",
    "            handle.remove()\n",
    "\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            handle = module.register_forward_hook(save_data)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _ = model(sample_data)\n",
    "                max_layer_output = max_outputs[-1]\n",
    "                module.weight.data /= max_layer_output\n",
    "                if hasattr(module, 'bias'):\n",
    "                    bias_scale = np.product(np.array(max_outputs))\n",
    "                    # print(f\"weight scale: {1/max_layer_output}, bias_scale: {1/bias_scale}\")\n",
    "                    module.bias.data /= bias_scale\n",
    "            handle.remove()\n",
    "    return max_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model = copy.deepcopy(folded_model)\n",
    "sample_data = next(iter(test_loader))[0].cuda()\n",
    "percentile = 99.99\n",
    "normalize_outputs(norm_model, sample_data=sample_data, percentile=percentile, max_outputs=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(norm_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_layers = nn.Sequential(\n",
    "    folded_model.conv1,\n",
    "    folded_model.bn1,\n",
    "    folded_model.relu,\n",
    ")\n",
    "\n",
    "ann = nn.Sequential(\n",
    "    folded_model.maxpool,\n",
    "    folded_model.layer1,\n",
    "    folded_model.layer2,\n",
    "    folded_model.layer3,\n",
    "    folded_model.layer4,\n",
    "    folded_model.avgpool,\n",
    "    nn.Flatten(),\n",
    "    folded_model.fc\n",
    ")\n",
    "\n",
    "composed_model = nn.Sequential(\n",
    "    preprocess_layers,\n",
    "    ann\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(composed_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_output_comparison_new(folded_model, norm_model, sample_input=next(iter(valid_loader))[0].cuda(), every_n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for exponent in range(3, 6):\n",
    "    t_max = 2**exponent\n",
    "    snn = quartz.from_torch.from_model(ann, t_max=t_max, add_spiking_output=True).eval()\n",
    "    print(f\"percentile: {percentile}, t_max: {t_max}\")\n",
    "    accuracy = get_accuracy(snn, valid_loader, device, preprocess=preprocess_layers, t_max=t_max, print_early_spikes=True, print_output_time=True)\n",
    "    # np.save(f\"{accuracy}_accuracy_{t_max}_t_max.npy\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "caf264bf03997fa53b380c84044763293a7a6f8ebb5555ee5243fd4d1f495be6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
