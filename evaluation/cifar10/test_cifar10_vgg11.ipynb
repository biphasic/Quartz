{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sinabs\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import sinabs.layers as sl\n",
    "import numpy as np\n",
    "import quartz\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from quartz.utils import get_accuracy, encode_inputs, decode_outputs, normalize_outputs, plot_output_comparison, plot_output_comparison_new, normalize_weights, count_n_neurons, fuse_all_conv_bn, n_operations, omega_read, omega_write\n",
    "from typing import List\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models.vgg import vgg11_bn\n",
    "\n",
    "model = vgg11_bn(pretrained=True)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)/1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_count = 0\n",
    "for module in model.modules():\n",
    "    if isinstance(module, (nn.ReLU, nn.ReLU6)):\n",
    "        module.inplace = False\n",
    "        relu_count += 1\n",
    "print(f\"Model contains {relu_count} relu layers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "valid_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, shuffle=False, batch_size=batch_size, num_workers=4)\n",
    "snn_loader = DataLoader(dataset=valid_dataset, shuffle=True, batch_size=16, num_workers=4)\n",
    "norm_loader = DataLoader(dataset=valid_dataset, shuffle=True, batch_size=10000, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = count_n_neurons(model.cpu(), next(iter(valid_loader))[0][:1], add_last_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folded_model = copy.deepcopy(model)\n",
    "fuse_all_conv_bn(folded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "flops = FlopCountAnalysis(folded_model, next(iter(valid_loader))[0])\n",
    "print(flops.total()/1e6/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_accuracy(folded_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for percentile in [98, 99, 99.5, 99.9, 99.99, 99.999]:\n",
    "    norm_model = copy.deepcopy(folded_model)\n",
    "    normalize_outputs(norm_model.cpu(), sample_data=next(iter(norm_loader))[0], percentile=percentile, max_outputs=[])\n",
    "\n",
    "    preprocess_layers = copy.deepcopy(norm_model.features[0]).to(device)\n",
    "    for exponent in range(4, 7):\n",
    "        t_max = 2**exponent\n",
    "        snn = copy.deepcopy(norm_model)\n",
    "        quartz.from_torch.from_model2(snn, t_max=t_max, add_spiking_output=False)\n",
    "        snn.features = snn.features[1:]\n",
    "        snn = nn.Sequential(*snn.features, nn.Flatten(2), *snn.classifier, quartz.IF(t_max=t_max, rectification=False))\n",
    "        metric = get_accuracy(snn, snn_loader, device, t_max=t_max, calculate_early_spikes=True, calculate_output_time=True, preprocess=preprocess_layers,)\n",
    "        n_synops = torch.stack([layer.n_ops for layer in snn if isinstance(layer, sl.StatefulLayer)]).sum().item()\n",
    "        metric[t_max]['n_synops'] = n_synops\n",
    "        metric[t_max]['n_neurons'] = n_neurons\n",
    "        metric[t_max]['n_ops'] = n_operations(n_neurons, t_max, n_synops)\n",
    "        metric[t_max]['read_ops'] = omega_read(n_neurons, t_max, n_synops)\n",
    "        metric[t_max]['write_ops'] = omega_write(n_neurons, t_max, n_synops)\n",
    "        if percentile in stats.keys():\n",
    "            stats[percentile].update(metric)\n",
    "        else:\n",
    "            stats[percentile] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cifar10-results.pkl', 'wb') as file:\n",
    "    pickle.dump(stats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_ann = copy.deepcopy(norm_model)\n",
    "# for exponent in range(1, 7):\n",
    "#     t_max = 2**exponent\n",
    "#     def quantize(module, input, output):\n",
    "#         return (output * t_max).round() / t_max\n",
    "\n",
    "#     for module in q_ann.modules():\n",
    "#         if isinstance(module, nn.ReLU):\n",
    "#             module.register_forward_hook(quantize)\n",
    "#     q_ann.classifier[-1].register_forward_hook(quantize)\n",
    "\n",
    "#     accuracy = get_accuracy(q_ann, valid_loader, device)\n",
    "#     print(f\"{t_max} time steps: {round(accuracy, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quantization_error(model1, model2, sample_input, savefig=None):\n",
    "    sns.set_theme(style=\"dark\")\n",
    "    output_layer_pairs = [((name1, layer1), (name2, layer2)) for (name1, layer1), (name2, layer2) in zip(model1.named_modules(), model2.named_modules()) if isinstance(layer1, (nn.Conv2d, nn.Linear)) and isinstance(layer2, (nn.Conv2d, nn.Linear))]\n",
    "    n_output_layers = len(output_layer_pairs)\n",
    "\n",
    "    model1 = model1.eval()\n",
    "    model2 = model2.eval()\n",
    "\n",
    "    activations1 = []\n",
    "    activations2 = []\n",
    "    def hook1(module, inp, output):\n",
    "        activations1.append(output.detach())\n",
    "\n",
    "    t_max = 2**4\n",
    "    def quantize(module, input, output):\n",
    "        q_output = (output * t_max).round() / t_max\n",
    "        activations2.append(q_output.detach())\n",
    "        return q_output\n",
    "\n",
    "    distances = []\n",
    "    for i, ((name1, layer1), (name2, layer2)) in enumerate(output_layer_pairs):\n",
    "        if isinstance(layer1, (nn.Conv2d, nn.Linear)):\n",
    "            handle1 = layer1.register_forward_hook(hook1)\n",
    "            handle2 = layer2.register_forward_hook(quantize)\n",
    "\n",
    "            model1(sample_input)\n",
    "            model2(sample_input)\n",
    "\n",
    "            print(len(activations1), len(activations2))\n",
    "            difference = (activations1[-1] - activations2[-1])**2\n",
    "            distance = difference.sum() / activations1[-1].numel()\n",
    "            distances.append(distance.item())\n",
    "\n",
    "            activations1 = []\n",
    "            activations2 = []\n",
    "            handle1.remove()\n",
    "            # handle2.remove()\n",
    "            # not removing quantization handle here\n",
    "\n",
    "    axis = sns.barplot(x=np.arange(n_output_layers), y=distances)\n",
    "    axis.set_yscale(\"log\")\n",
    "    # axes[i].set_xlabel(f\"Original activations layer {name1}\")\n",
    "    # axes[i].set_ylabel('Normalised activations')\n",
    "    # axes[i].grid(True)\n",
    "\n",
    "    if savefig:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activation = {}\n",
    "def hook(module, input, output):\n",
    "    test_activation[module] = output.detach()\n",
    "    return torch.ones_like(output)\n",
    "\n",
    "model = nn.Linear(1, 1)\n",
    "model.register_forward_hook(get_activation('fc'))\n",
    "\n",
    "outputs = model(torch.randn(1, 1))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = copy.deepcopy(norm_model)\n",
    "\n",
    "sample_input = next(iter(valid_loader))[0].cuda()\n",
    "plot_quantization_error(norm_model, q_model, sample_input=sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [6.208464128576452e-06, 8.805314791970886e-06, 1.2459289791877382e-05, 1.2434165910235606e-05, 1.755043922457844e-05, 1.7589043636689894e-05, 3.5205608583055437e-05, 2.6136451197089627e-05, 2.123976628354285e-05, 2.2427710064221174e-05, 0.0005176494014449418]\n",
    "\n",
    "sns.barplot(x=np.arange(len(data)), y=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_output_comparison_new(folded_model.cuda(), norm_model.cuda(), sample_input=next(iter(valid_loader))[0].cuda(), every_n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ops = [layer.n_ops for layer in snn.modules() if isinstance(layer, sl.StatefulLayer)]\n",
    "torch.stack(n_ops).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_synops_rate = 576e6\n",
    "\n",
    "3*n_synops_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c00e5e7c7a569083cb991dfa106f557879cc0d1d84bf5b9d92fbb6bf680d358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
