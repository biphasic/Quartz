{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.quantization\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from quartz.utils import get_accuracy, encode_inputs, decode_outputs, plot_output_histograms\n",
    "import sinabs\n",
    "import sinabs.layers as sl\n",
    "import quartz\n",
    "from copy import deepcopy\n",
    "from cifar_model import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device = 'cuda'\n",
    "\n",
    "valid_dataset = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset=valid_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 99.9999\n",
    "ann = torch.load(f\"./cifar-convnet-normalised-{percentile}.pth\", map_location=torch.device(device)).eval()\n",
    "ann;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short = deepcopy(ann[:7])\n",
    "snn = quartz.from_torch.from_model(short, t_max=2**5+1, add_spiking_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = next(iter(test_loader))[0]\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ann = deepcopy(ann)\n",
    "for exponent in range(4, 8):\n",
    "    t_max = 2**exponent+1\n",
    "    def quantize(module, input, output):\n",
    "        return (output * t_max).round() / t_max\n",
    "\n",
    "    for module in q_ann.children():\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            module.register_forward_hook(quantize)\n",
    "    q_ann[-1].register_forward_hook(quantize)\n",
    "\n",
    "    accuracy = get_accuracy(q_ann, valid_loader, device)\n",
    "    print(f\"{t_max} time steps: {round(accuracy, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = next(iter(test_loader))[0]\n",
    "output_layers = [layer for layer in ann.children() if isinstance(layer, nn.ReLU)]\n",
    "output_layers += [ann[-1]]\n",
    "# plot_output_histograms(ann, sample_data, )\n",
    "output_layers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(ann, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponent = 4\n",
    "snn = quartz.from_torch.from_model(ann, t_max=2**exponent+1, add_spiking_output=True)\n",
    "snn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ann.cuda()\n",
    "\n",
    "for exponent in range(4, 8):\n",
    "    t_max = 2**exponent+1\n",
    "    snn = quartz.from_torch.from_model(ann, t_max=t_max, add_spiking_output=True).to(device).eval()\n",
    "    snn[-1].rectification = False\n",
    "    accuracy = get_accuracy(snn, valid_loader, device, t_max=t_max)\n",
    "    print(f\"{t_max} time steps: {round(accuracy, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 2**3+1\n",
    "images, label = next(iter(valid_loader))\n",
    "spikes = encode_inputs(images, t_max=t_max).to(device)\n",
    "snn = quartz.from_torch.from_model(ann, t_max=t_max, add_spiking_output=True).to(device).eval()\n",
    "output_layers = [child for name, child in snn.named_children() if isinstance(child, sl.StatefulLayer)]\n",
    "\n",
    "plot_output_histograms(snn, spikes, output_layers, t_max=t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 2**3+1\n",
    "def quantize(module, input, output):\n",
    "    return (output * t_max).int() / t_max\n",
    "\n",
    "for module in ann.children():\n",
    "    if isinstance(module, nn.ReLU):\n",
    "        module.register_forward_hook(quantize)\n",
    "ann[-1].register_forward_hook(quantize)\n",
    "\n",
    "param_layers = [child for name, child in ann.named_children() if isinstance(child, (nn.Conv2d, nn.Linear))]\n",
    "output_layers = [child for name, child in ann.named_children() if isinstance(child, nn.ReLU)]\n",
    "output_layers += [param_layers[-1]]\n",
    "plot_output_histograms(ann, images.to(device), output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf264bf03997fa53b380c84044763293a7a6f8ebb5555ee5243fd4d1f495be6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
