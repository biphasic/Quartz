{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sinabs\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import sinabs.layers as sl\n",
    "import numpy as np\n",
    "import quartz\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from quartz.utils import get_accuracy, encode_inputs, decode_outputs, normalize_outputs, plot_output_comparison, plot_output_comparison_new, normalize_weights, count_n_neurons, fuse_all_conv_bn, n_operations, omega_read, omega_write\n",
    "from typing import List\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.relu2(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512,  (1024,2), 1024]\n",
    "    # cfg = [64, (256,2), (512,2), 512, (1024,2), (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "        self.avg_pool = nn.AvgPool2d(2, stride=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = MobileNet().eval()\n",
    "state_dict = {k[7:]:v for k, v in torch.load('mobilenetv1.pth')['net'].items()}\n",
    "# state_dict = {k[7:]:v for k, v in torch.load('mobilenetv1-short.pth')['net'].items()}\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "valid_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, shuffle=False, batch_size=batch_size, num_workers=4)\n",
    "snn_loader = DataLoader(dataset=valid_dataset, shuffle=True, batch_size=8, num_workers=4)\n",
    "norm_loader = DataLoader(dataset=valid_dataset, shuffle=True, batch_size=10000, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = count_n_neurons(model.cpu(), next(iter(valid_loader))[0][:1], add_last_layer=True)\n",
    "n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)/1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folded_model = copy.deepcopy(model)\n",
    "fuse_all_conv_bn(folded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(folded_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_accuracy(norm_model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for percentile in [99.5, 99.9, 99.99, 99.999]:\n",
    "    norm_model = copy.deepcopy(folded_model)\n",
    "    normalize_outputs(norm_model.cpu(), sample_data=next(iter(norm_loader))[0][::3], percentile=percentile, max_outputs=[])\n",
    "    with torch.no_grad():\n",
    "        norm_model.linear.weight *= 2\n",
    "    preprocess_layers = copy.deepcopy(norm_model.conv1).to(device)\n",
    "\n",
    "    for t_max in [64, 128]:\n",
    "        snn = copy.deepcopy(norm_model).to(device)\n",
    "        snn.conv1 = nn.Identity()\n",
    "        quartz.from_torch.from_model2(snn, t_max=t_max)\n",
    "        snn = nn.Sequential(snn, quartz.IF(t_max=t_max, rectification=False))\n",
    "        metric = get_accuracy(snn, snn_loader, device, t_max=t_max, calculate_early_spikes=True, calculate_output_time=True, preprocess=preprocess_layers,)\n",
    "        n_synops = torch.stack([layer.n_ops for layer in snn if isinstance(layer, sl.StatefulLayer)]).sum().item()\n",
    "        metric[t_max]['n_synops'] = n_synops\n",
    "        metric[t_max]['n_neurons'] = n_neurons\n",
    "        metric[t_max]['n_ops'] = n_operations(n_neurons, t_max, n_synops)\n",
    "        metric[t_max]['read_ops'] = omega_read(n_neurons, t_max, n_synops)\n",
    "        metric[t_max]['write_ops'] = omega_write(n_neurons, t_max, n_synops)\n",
    "        if percentile in stats.keys():\n",
    "            stats[percentile].update(metric)\n",
    "        else:\n",
    "            stats[percentile] = metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cifar10-results-mobilenet.pkl', 'wb') as file:\n",
    "    pickle.dump(stats, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
